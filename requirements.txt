# Sumerian NMT Dependencies (H100/CUDA 12.1+ Optimized)
# Install with: pip install -r requirements.txt
# Or use: pip install -e . (with pyproject.toml)

# =============================================================================
# PyTorch - Core deep learning framework (H100/CUDA 12.1+)
# =============================================================================
torch>=2.2.0
torchvision
torchaudio

# =============================================================================
# LLM Training Stack (Axolotl + Flash Attention)
# =============================================================================
transformers>=4.40.0
accelerate>=0.30.0
peft>=0.10.0
bitsandbytes>=0.43.0
datasets
trl>=0.8.0

# Axolotl - LLM fine-tuning framework
# Install separately: pip install axolotl[flash-attn,deepspeed]
# Or: pip install 'axolotl[flash-attn,deepspeed] @ git+https://github.com/OpenAccess-AI-Collective/axolotl'

# Flash Attention 2 (H100/A100 optimized)
# Requires: pip install ninja packaging
# Then: pip install flash-attn>=2.5.0 --no-build-isolation
flash-attn>=2.5.0

# =============================================================================
# Graph Augmentation & Data Processing
# =============================================================================
networkx>=3.1
python-Levenshtein>=0.21
pandas>=2.0
numpy>=1.24
scipy
pyarrow>=12.0
lxml>=4.9

# =============================================================================
# Evaluation Metrics
# =============================================================================
sacrebleu>=2.3
evaluate>=0.4
bert-score>=0.3.13
absl-py
rouge_score

# =============================================================================
# Utilities
# =============================================================================
tqdm>=4.65
sentencepiece>=0.1.99
protobuf>=3.20

# =============================================================================
# Tokenizer Experiments
# =============================================================================
morfessor>=2.0
